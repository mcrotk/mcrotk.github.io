<html>
<head>
<title>LNCIS 2006 Notes</title>
<link rel="stylesheet" type="text/css" href="../styles_mcrotk.css" />
</head>

<body>
<script src=../menu_mcrotk_up.js></script>
<td class="notecell">

<blockquote>
<div class="pubentry">
<div class="author">R. Cogill, M. Rotkowitz, B. Van Roy, and S. Lall</div class="author">
<div class="article">
<a class="article" href="../publications/lncis06_notes.html">
An Approximate Dynamic Programming Approach to Decentralized Control of Stochastic Systems</a class="article">
</div class="article">
Lecture Notes in Control and Information Sciences vol. 329,
Control of Uncertain Systems: Modelling, Approximation, and Design,<br>
(A Workshop on the Occasion of Keith Glover's 60th Birthday),
pp. 243-256, April 2006.
<div class="plinks">
<a href="../publications/lncis06_notes.html">[abstract]
</a>
<a href="../publications/lncis_2006.pdf">[.pdf]</a>
</div class="plinks"></div class="pubentry">
</blockquote>


<h3 class="abstract">
Abstract
</h3 class="abstract">
<blockquote>
<p class="abstract">

We consider the problem of computing decentralized control policies
for stochastic systems with finite state and action spaces. Synthesis of optimal decentralized
policies for such problems is known to be NP-hard [1]. Here we focus
on methods for efficiently computing meaningful suboptimal decentralized control
policies. The algorithms we present here are based on approximation of optimal Qfunctions.
We show that the performance loss associated with choosing decentralized
policies with respect to an approximate Q-function is related to the approximation
error.

</p class="abstract">
</blockquote>


</td class="notecell">
</tr>
</table>
</body>
</html>
