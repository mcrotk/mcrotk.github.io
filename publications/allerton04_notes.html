<html>
<head>
<title>Allerton 2004 Notes</title>
<link rel="stylesheet" type="text/css" href="../styles_mcrotk.css" />
</head>

<body>
<script src=../menu_mcrotk_up.js></script>
<td class="notecell">

<blockquote>
<div class="pubentry">
<div class="author">R. Cogill, M. Rotkowitz, B. Van Roy, and S. Lall</div class="author">
<div class="article">
<a class="article" href="../publications/allerton04_notes.html">An Approximate Dynamic Programming Approach to Decentralized Control of Stochastic Systems</a class="article">
</div class="article">
Proceedings of the 2004 Allerton Conference on Communication, Control, and Computing, September 2004.
<div class="plinks">
<a href="../publications/allerton04_notes.html">[abstract]
</a>
<a href="../publications/allerton04.pdf">[.pdf]</a>
<a href="../publications/allerton04.ps">[.ps]</a>
</div class="plinks"></div class="pubentry">
</blockquote>


<h3 class="abstract">
Abstract
</h3 class="abstract">
<blockquote>
<p class="abstract">

In this paper we consider the problem of computing decentralized control
policies for stochastic systems with finite state and action spaces.
Synthesis of optimal decentralized policies for such problems is known to
be NP-hard. Here we focus on methods for efficiently computing meaningful
suboptimal decentralized control policies. The algorithms we present here
are based on approximation of optimal Q-functions. We show that the
performance loss associated with choosing decentralized policies with
respect to an approximate Q-function is related to the approximation
error. We demonstrate the methods developed in this paper with an example
of load balancing in a queuing network.

</p class="abstract">
</blockquote>


</td class="notecell">
</tr>
</table>
</body>
</html>
